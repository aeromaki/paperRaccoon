{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Reward Model Train</h2>\n",
    "\n",
    "보상모델을 훈련시키자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun 11 01:31:12 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    41W / 300W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install nvidia-ml-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LEDModel, LEDTokenizer, BartModel\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/root/.cache/huggingface/datasets/aeromaki___parquet/aeromaki--arxiv_noised_small-203d8e72f8332c5e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c774c8830e2a45189bbe35e9f468c0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset을 만들긴 만들었는데 추가한 noised 부분은 결과적으로 안 씀...\n",
    "dataset = load_dataset(\"aeromaki/arxiv_noised_small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LEDTokenizer.from_pretrained(\"allenai/led-large-16384-arxiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longformer는 대부분 token에 sliding window 방식의 local attention만을 적용하지만, 일부 special token에 대해 global attention 연산을 적용함\n",
    "# 이를 위해 global attention을 적용할 special token을 지정할 mask가 forward에 필요함\n",
    "# 별로 중요한 부분은 아님\n",
    "\n",
    "def generate_global_attention_mask(tokenizer, input_ids):\n",
    "    mask = torch.zeros_like(input_ids)\n",
    "    mask[((input_ids == tokenizer.bos_token_id) | (input_ids == tokenizer.eos_token_id)).nonzero(as_tuple=True)] = 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reward Model\n",
    "# 시행착오를 거치면서 두 개의 encoder를 사용하는 이상한 구조가 됨...\n",
    "\n",
    "\n",
    "# self.led :\n",
    "    # longformer의 encoder (allenai/led-large-16384-arxiv에서 encoder만 가져옴)\n",
    "    # 원문을 입력으로 받음\n",
    "\n",
    "# self.bart :\n",
    "    # bart-large의 encoder (facebook/bart-large에서 encoder만 가져옴)\n",
    "    # 비교할 요약문 둘을 입력으로 받음\n",
    "\n",
    "    # 두 모델을 아무렇게나 합쳐도 되는 건가? 싶을 수도 있는데 tokenizer의 vocab이 완전히 일치해서 괜찮을 듯? (둘 다 d_model도 1024로 동일)\n",
    "    # 나머지는 head가 알아서 해줄 거란 믿음을 갖고 돌렸는데 괜찮게 나옴\n",
    "\n",
    "# self.flatten :\n",
    "    # d_model 기준으로 led encoder와 bart encoder의 last hidden state를 concatenate한 걸 납작하게 만들어줌 (d_model -> 1)\n",
    "\n",
    "# head :\n",
    "    # scalar 값을 산출\n",
    "\n",
    "\n",
    "class RewardModel(nn.Module):\n",
    "    def __init__(self, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.led = LEDModel.from_pretrained(\"allenai/led-large-16384-arxiv\").get_encoder()\n",
    "        self.bart = BartModel.from_pretrained(\"facebook/bart-large\").get_encoder()\n",
    "\n",
    "        self.flatten = nn.Linear(1024, 1)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(17408, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, summary_input_ids, global_attention_mask=None):\n",
    "        hidden_state = self.led(input_ids, global_attention_mask=global_attention_mask).last_hidden_state\n",
    "        output = torch.zeros((hidden_state.shape[0], 16384, 1024)).to(self.device) # head가 fixed size만 받을 수 있으므로 0으로 padding\n",
    "        output[:, :hidden_state.shape[1], :] = hidden_state\n",
    "\n",
    "        bart_hidden_state = self.bart(summary_input_ids).last_hidden_state\n",
    "        bart_output = torch.zeros((bart_hidden_state.shape[0], 1024, 1024)).to(self.device) # head가 fixed size만 받을 수 있으므로 0으로 padding\n",
    "        bart_output[:, :bart_hidden_state.shape[1], :] = bart_hidden_state\n",
    "\n",
    "        concat = torch.cat([output.repeat((summary_input_ids.shape[0], 1, 1)), bart_output], dim=1)\n",
    "        # concat = torch.cat([output.repeat((summary_input_ids.shape[0], 1, 1)), bart_output], dim=1).detach()\n",
    "            # augmentated arxiv dataset으로는 flatten과 head만 update함\n",
    "            # (왠지 flatten과 head가 random initialized된 상태에서 encoder까지 한 번에 train하려니 제대로 안 돼서 이렇게 함)\n",
    "            # openai feedback dataset으로는 encoder까지 전부 update하므로(이건 괜찮게 됨) detach를 사용하지 않음\n",
    "        concat = self.flatten(concat)\n",
    "        result = self.head(concat.transpose(1, 2))\n",
    "\n",
    "        return result.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/led-large-16384-arxiv were not used when initializing LEDModel: ['final_logits_bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing LEDModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LEDModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "model = RewardModel().to(device)\n",
    "# model.load_state_dict(torch.load(\"reward_model_openai_2190.pth\"))\n",
    "    # 저장해둔 모델이 있을 경우 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function으로 minus log sigmoid를 사용 (openai 논문에서 쓰길래 그냥 따라함)\n",
    "# output[0]이 정답, output[1]이 오답으로 위치가 정해져 있음\n",
    "class Criterion():\n",
    "    def __init__(self):\n",
    "        self.logsig = nn.LogSigmoid()\n",
    "    def loss(self, output):\n",
    "        return -self.logsig(output[0] - output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = Criterion()\n",
    "scaler = GradScaler() # fp16으로 훈련시키기 위해 필요 (안 쓰면 A100 80GB 써도 VRAM 부족해서 터짐!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvidia_smi\n",
    "\n",
    "nvidia_smi.nvmlInit()\n",
    "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0) # GPU VRAM 사용률 확인하기 위해 사용 (안 중요함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation 1\n",
    "# 오답으로 무작위 단어들로 이루어진 abstract와 비슷한 길이의 문장을 만듦\n",
    "def arxivrand(row):\n",
    "    merged_1 = row[\"abstract\"]\n",
    "    \n",
    "    rand = torch.randint(4, tokenizer.vocab_size - 1, tokenizer.encode(merged_1, return_tensors=\"pt\")[:,1:-1].shape)\n",
    "    merged_0 = tokenizer.batch_decode(rand[:,:-torch.randint(0, 7, (1,))[0]], skip_special_tokens=True)[0]\n",
    "                                      \n",
    "    return [merged_1, merged_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation 2\n",
    "# 오답으로 abstract의 끝부분을 복사하여 망가진 text를 만듦\n",
    "def pad_dup_back(row):\n",
    "    merged_1 = row[\"abstract\"]\n",
    "    l = torch.randint(3, 6, (1,))[0]\n",
    "    r = len(merged_1) // l\n",
    "    dup = merged_1[-r:]\n",
    "    merged_0 = (merged_1[:r] + dup * (l-1))[:-1]\n",
    "    \n",
    "    return [merged_1, merged_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation 3\n",
    "# 오답으로 아예 다른 논문의 abstract를 사용\n",
    "def other(row):\n",
    "    return [row[\"abstract\"], dataset[\"train\"][torch.randint(0, 10000, (1,))[0]][\"abstract\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용\n",
    "# 사용할 augmentation 방법을 선택하여 적용할 수 있음\n",
    "def update(d, aug):\n",
    "    put = tokenizer.batch_encode_plus(aug(d), return_tensors=\"pt\", padding=True).input_ids\n",
    "    \n",
    "    if put.shape[1] > 1024:\n",
    "        put = put[:,:1024].to(device)\n",
    "    else:\n",
    "        put = put.to(device)\n",
    "    \n",
    "    art = tokenizer.encode(d[\"article\"], return_tensors=\"pt\").to(device)\n",
    "    att = generate_global_attention_mask(tokenizer, art).to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    with autocast():\n",
    "        res = model(art, put, att)\n",
    "        loss = criterion.loss(res)\n",
    "        scaler.scale(loss).backward()\n",
    "        t = loss.item()\n",
    "        del art\n",
    "        del put\n",
    "        del att\n",
    "        del res\n",
    "        del loss\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# arxiv dataset으로 학습\n",
    "\n",
    "i = 0 # zip 쓰니 dataset에 대한 iteration이 column 기준으로 바뀌어서(dictionary라 그런가?) 따로 빼줌\n",
    "s = torch.Tensor([0, 0, 0]) # 평균 loss 계산용\n",
    "\n",
    "save_size = 1000\n",
    "check_size = 100\n",
    "\n",
    "model.train()\n",
    "for d in tqdm(dataset[\"train\"]):\n",
    "    i += 1\n",
    "\n",
    "    s[0] += update(d, pad_dup_back)\n",
    "    s[1] += update(d, arxivrand)\n",
    "    s[2] += update(d, other)\n",
    "    \n",
    "    if i % save_size == 0:\n",
    "        torch.save(model.state_dict(), f\"./reward_model_{i}.pth\")\n",
    "    if i % check_size == 0:\n",
    "        info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "        print(f\"epoch: {i} / loss: {s / check_size} / GPU: {100 * (1 - info.free / info.total)}% used\")\n",
    "        s = torch.Tensor([0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: 42.48138427734375% used\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "print(f\"GPU: {100 * (1 - info.free / info.total)}% used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"./reward_model_openai_2190.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset summarize_from_feedback (/root/.cache/huggingface/datasets/openai___summarize_from_feedback/comparisons/0.0.0/483f970ceb55b926b0a087ef4f678ab1b089bc8174a107a452c6152e88af7ff0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390a2bafd0ce4c5d9ee2c85e9466129c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset2 = load_dataset(\"openai/summarize_from_feedback\", \"comparisons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai dataset 전처리\n",
    "# openai dataset은 짧은 글에 대한 짧은 요약을 제공하기 때문에 긴 글을 받아 긴 글을 생성하도록 학습된 요약 모델과 그 요약 모델을 평가하도록 학습시킬 보상 모델에는 부적합함\n",
    "# 하지만 '진짜' 인간 피드백인 이 데이터셋을 쓰지 않는 것은 너무나도 아까운 일이기 때문에 여러 개의 짧은 글을 이어 붙여 하나의 긴 글로 만드는 방식을 사용함\n",
    "# 짧은 그대로 넣었을 때는 loss가 전혀 개선되지 않았는데 여러 개 이어붙여 넣는 방식을 사용하니 즉시 효과가 나타남!\n",
    "\n",
    "def redditpreprocessor(rows):\n",
    "  text = \"\\n\\n\".join([\"TITLE: \" + orig[\"title\"] + \"POST: \" + orig[\"post\"] for orig in rows[\"info\"]])\n",
    "\n",
    "  return text, [\"\\n\\n\".join([\"SUMMARY: \" + r[c][\"text\"] for r, c in zip(rows[\"summaries\"], rows[\"choice\"])]), \"\\n\\n\".join([\"SUMMARY: \" + r[1-c][\"text\"] for r, c in zip(rows[\"summaries\"], rows[\"choice\"])])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = Criterion()\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 2001/4642 [00:00<00:00, 2867.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2010 / loss: 0.06071450511614482 / GPU: 64.26849365234375% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 2025/4642 [00:16<00:30, 86.41it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2040 / loss: 0.574515414237976 / GPU: 64.26849365234375% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 2064/4642 [00:46<03:13, 13.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2070 / loss: 0.4203218460083008 / GPU: 64.26849365234375% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 2086/4642 [00:59<05:39,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2100 / loss: 0.16639448006947835 / GPU: 64.26849365234375% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2128/4642 [01:28<14:06,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2130 / loss: 0.2298765738805135 / GPU: 64.26849365234375% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 2158/4642 [01:50<23:19,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2160 / loss: 0.06116012136141459 / GPU: 64.26849365234375% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2190/4642 [02:14<02:30, 16.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2190 / loss: 0.17225597500801088 / GPU: 64.26849365234375% used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# openai dataset으로 학습\n",
    "\n",
    "i = 0\n",
    "s = 0\n",
    "num_batch = 20\n",
    "model.train()\n",
    "for d in tqdm(range(0, dataset2[\"train\"].num_rows-num_batch, num_batch)):\n",
    "    i += 1\n",
    "\n",
    "    art, put = redditpreprocessor(dataset2[\"train\"][d:d+num_batch])\n",
    "    put = tokenizer.batch_encode_plus(put, return_tensors=\"pt\", padding=True).input_ids\n",
    "    \n",
    "    if put.shape[1] > 1024:\n",
    "        continue\n",
    "    else:\n",
    "        put = put.to(device)\n",
    "    \n",
    "    art = tokenizer.encode(art, return_tensors=\"pt\").to(device)\n",
    "    att = generate_global_attention_mask(tokenizer, art).to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    with autocast():\n",
    "        res = model(art, put, att)\n",
    "        loss = criterion.loss(res)\n",
    "        scaler.scale(loss).backward()\n",
    "        s += loss.item()\n",
    "        del art\n",
    "        del put\n",
    "        del att\n",
    "        del res\n",
    "        del loss\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        torch.save(model.state_dict(), f\"./reward_model_openai_{i}.pth\")\n",
    "    if i % 30 == 0:\n",
    "        info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "        print(f\"epoch: {i} / loss: {s / 30} / GPU: {100 * (1 - info.free / info.total)}% used\")\n",
    "        s = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>pretrained model</h3>\n",
    "\n",
    "필요하면 jupyter 환경에서 gdown으로 불러올 수 있음\n",
    "\n",
    "https://drive.google.com/file/d/13AJNdIcUjsa3EXKIJvJrzALNf4Fr6y1V/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-123.8978, -127.6668], device='cuda:0') tensor(0.0228, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 이 밑은 그냥 테스트용임 (볼 필요 없음)\n",
    "\n",
    "label = 10079\n",
    "wrong = 2170\n",
    "\n",
    "wrong_ = 'the multiple quantum ( mq ) nmr dynamics in the system of equivalent spins with the dipolar ordered initial state is considered. \\n the high symmetry of the hamiltonian responsible for the mq nmr dynamics ( the mq hamiltonian ) is used in order to develop the analytical and numerical methods for an investigation of the mq nmr dynamics in the systems consisting of hundreds of spins from `` the first principles ''. \\n we obtain the dependence of the intensities of the mq nmr coherences on'\n",
    "#put = tokenizer.batch_encode_plus([dataset[\"train\"][label][\"abstract\"], wrong_], return_tensors=\"pt\", padding=True).input_ids.to(\"cuda\")\n",
    "put = tokenizer.batch_encode_plus([dataset[\"train\"][label][\"abstract\"], dataset[\"train\"][wrong][\"abstract\"]], return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "art = tokenizer.encode(dataset[\"train\"][label][\"article\"], return_tensors=\"pt\").to(device)\n",
    "att = generate_global_attention_mask(tokenizer, art).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    res = model(art, put, att)\n",
    "    loss = criterion.loss(res)\n",
    "print(res, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a universal quantum simulator would enable efficient simulation of quantum dynamics by implementing quantum - simulation algorithms on a quantum computer. \\n specifically the quantum simulator would efficiently generate qubit - string states that closely approximate physical states obtained from a broad class of dynamical evolutions. \\n i provide an overview of theoretical research into universal quantum simulators and the strategies for minimizing computational space and time costs. \\n applications to simulating many - body quantum simulation and solving linear equations are discussed    computing, quantum algorithms, quantum simulation',\n",
       " \"the multiple quantum ( mq ) nmr dynamics in the system of equivalent spins with the dipolar ordered initial state is considered. \\n the high symmetry of the hamiltonian responsible for the mq nmr dynamics ( the mq hamiltonian ) is used in order to develop the analytical and numerical methods for an investigation of the mq nmr dynamics in the systems consisting of hundreds of spins from `` the first principles ''. \\n we obtain the dependence of the intensities of the mq nmr coherences on their orders ( profiles of the mq nmr coherences ) for the systems of @xmath0 spins. \\n it is shown that these profiles may be well approximated by the exponential distribution functions. \\n we also compare the mq nmr dynamics in the systems of equivalent spins having two different initial states, namely the dipolar ordered state and the thermal equilibrium state in the strong external magnetic field.    * the multiple quantum nmr dynamics in systems of equivalent spins with the dipolar ordered initial state *    s.i.doronin, e.b.feldman and a.i.zenchuk    institute of problems of chemical physics, russian academy of sciences, chernogolovka, moscow reg. \\n, 142432, russia\")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][label][\"abstract\"], dataset[\"train\"][wrong][\"abstract\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
