{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-large-16384-arxiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"arxiv\"\n",
    "data_type = \"test\"\n",
    "\n",
    "with open(file=f\"../_FRIDGE/{dataset}/{data_type}_filtered.pickle\", mode='rb') as f:\n",
    "    arxiv_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "sample = deepcopy(arxiv_test[:30])\n",
    "del arxiv_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'article': tensor([   0, 1990,   59,  ...,  438,  479,    2]),\n",
       "  'abstract': tensor([    0,   627,   765,   111,  1385, 27185,  2192,     9,     5,  1230,\n",
       "           3778, 27840,   443, 22798,    31, 26713,  4193, 37613,     7, 16874,\n",
       "          24761, 26873,    32,  3373,   479,    13,   209,   414,  1437, 50118,\n",
       "              5, 46764,  3693,  1966,  8711,  2430, 22792,    13,     5,   675,\n",
       "          24414,     9,    59,   787,  1178, 40051,   288,   360,  2156,    53,\n",
       "              5,   476,  8576,  1966,  8711,    10, 27697,  1233,  4996,    11,\n",
       "             42,    86, 22455,   479,  1437, 50118,    10,    92,  5448,     9,\n",
       "              5,  9726,     9,    41, 23930,   111,  1683,    11,  8576,    16,\n",
       "           1850,     8,    24,    16,  2305,    14,     5, 18918,    12,  1208,\n",
       "            675, 24414,    16,    10, 46336,     9,     5, 27185,  2192,    31,\n",
       "              5, 22455,     9,   787,  1178, 40051,   134,    68, 27779,   360,\n",
       "            479,  1437,  1437,  1437,     5,  7241,  1975,   368, 47114,  8047,\n",
       "             13,     5,  1230,  3778, 27840,   443, 22798,     8,    13,     5,\n",
       "          22798,     9,     5,    65, 10134,    86, 22455,    11,     5,  3285,\n",
       "          32515,  2156, 12712,    13,     5,  1086,  4118,  4943,   545,     8,\n",
       "             13,     5,  4532,  1940,   675,     9,    42,  4943,   109,    45,\n",
       "            311,  5550,  2156,   941,    11,     5, 22455,     9,   787,  1178,\n",
       "          40051,   176,    68, 27779,   360,   479,  1437, 50118,    24, 14476,\n",
       "            136,     5, 24149,     9,     5,  8066,     9,   670,  1313, 22798,\n",
       "              9,     5,    59,   787,  1178, 40051,   288,    12,  1208, 22455,\n",
       "             11,     5,  4532,  1940,   675,     9,     5,  4118,  4943,   545,\n",
       "             11,     5,  3285, 32515,   479,  1437, 50118,   959,  2156,    10,\n",
       "           1122,  1966,    13,   414,    31,     5,  3174, 32515,  8711,    14,\n",
       "             89,    16,     5,   675, 24414,     9,    59,   787,  1178, 40051,\n",
       "            288,   360,    11,  3778, 27840,   443,   414,    11,     5,  4532,\n",
       "           1940,   675,     9,     5,  4943,   545,   129,   479,     2])},\n",
       " {'article': tensor([   0,  405,   16,  ..., 3416, 4283,    2]),\n",
       "  'abstract': tensor([    0,  1694,   892,     5, 10933,  4484,     9, 18629, 37836,    11,\n",
       "             10, 20572,   611, 11599, 34217,  4605,  3618,    31,  1337,  1715,\n",
       "            215,    25,  2422, 31065,   909,  4683, 47061,  2156, 30837, 22052,\n",
       "           2156,     8,  2680,    11,     5,   419,  9468,    19, 33463,   271,\n",
       "           5801, 42156,   479,  1437, 50118,    52, 15756, 44030, 27573,  4878,\n",
       "           8047,    13,     5, 18629,   352, 36033, 20572,   611, 11599, 34217,\n",
       "           4605,  3618,   479,  1437, 50118,    52,   465,    14,     5, 18629,\n",
       "          37836,    64,    45,    28, 12333,    13,    41, 40640,  6884,   636,\n",
       "           3618,   479,   959,  2156,    89,    16,    10,   778,     7, 14095,\n",
       "              5, 18629, 37836,    13,    41,    41,   354, 45051, 34217,  4605,\n",
       "           3618,   479,  1437, 50118,    52,    67,   311,   141,     7,  2559,\n",
       "          36033, 34217,  6995,    31, 23089, 19231,  1538, 34217,  6995,   479,\n",
       "              2])}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>we study the detectability of circular polarization in a stochastic gravitational wave background from various sources such as supermassive black hole binaries, cosmic strings, and inflation in the early universe with pulsar timing arrays. \\n we calculate generalized overlap reduction functions for the circularly polarized stochastic gravitational wave background. \\n we find that the circular polarization can not be detected for an isotropic background. however, there is a chance to observe the circular polarization for an anisotropic gravitational wave background. \\n we also show how to separate polarized gravitational waves from unpolarized gravitational waves.</s>'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = sample[1][\"abstract\"]\n",
    "tokenizer.decode(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3, 1, 50264]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_pure_rand(summ):\n",
    "    len_pad = torch.randint(2, 20, (1,))[0]\n",
    "    num_pad = torch.randint(3, 120//len_pad, (1,))[0]\n",
    "\n",
    "    MAX_ID = tokenizer.vocab_size - 1\n",
    "    pad = torch.randint(4, MAX_ID, (num_pad,))\n",
    "\n",
    "    return torch.cat((summ[:-1], pad.repeat(num_pad), torch.tensor([tokenizer.eos_token_id])))\n",
    "\n",
    "#tokenizer.decode(pad_pure_rand(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_dup_back(summ):\n",
    "    len_pad = torch.randint(2, 20, (1,))[0]\n",
    "    num_pad = torch.randint(3, 120//len_pad, (1,))[0]\n",
    "    \n",
    "    pad = summ[-len_pad:-1]\n",
    "\n",
    "    return torch.cat((summ[:-1], pad.repeat(num_pad), torch.tensor([tokenizer.eos_token_id])))\n",
    "\n",
    "#tokenizer.decode(pad_dup_back(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(summ):\n",
    "    ret = summ.clone().detach()\n",
    "    len_ret = ret.shape[0]\n",
    "\n",
    "    num_noise = torch.randint(min(len_ret, 3), len_ret, (1,))[0]\n",
    "\n",
    "    MAX_ID = tokenizer.vocab_size - 1\n",
    "    ret[torch.randint(1, len_ret-1, (num_noise,))] = torch.randint(4, MAX_ID-1, (num_noise,))\n",
    "    \n",
    "    return ret\n",
    "\n",
    "#tokenizer.decode(noise(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randmod(summ):\n",
    "    rand = torch.randint(0, 10, (1,))[0]\n",
    "\n",
    "    ret = []\n",
    "\n",
    "    if rand < 2:\n",
    "        ret = pad_pure_rand(summ)\n",
    "    elif rand < 4:\n",
    "        ret = pad_dup_back(summ)\n",
    "    else:\n",
    "        ret = noise(summ)\n",
    "    \n",
    "    return ret\n",
    "\n",
    "#tokenizer.decode(randmod(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug(dataset, data_type):\n",
    "    with open(file=f\"../_FRIDGE/{dataset}/{data_type}_filtered.pickle\", mode='rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    for i in tqdm(data):\n",
    "        i[\"noised\"] = randmod(i[\"abstract\"])\n",
    "    \n",
    "    with open(file=f\"../_FRIDGE/_aug/{dataset}_{data_type}_aug.pickle\", mode='wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6588/6588 [00:00<00:00, 24777.06it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset, data_type = \"pubmed\", \"test\"\n",
    "aug(dataset, data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file=f\"../_FRIDGE/_aug/{dataset}_{data_type}_aug.pickle\", mode='rb') as f:\n",
    "    result = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': tensor([    0,   260, 43537,  ..., 11048,   479,     2]),\n",
       " 'abstract': tensor([    0,  6762,    15,     5,  8819,     9,  6882,    11,  2221,  9554,\n",
       "           128,    29,  2199,    36,   181,   417,  4839,    34,    57, 20428,\n",
       "          1135,    63, 21087,    11,   823,   654,   207,     9,  1484,     8,\n",
       "            63,  2430,   913,    15,  1318,     9,   301,   479,  1437, 50118,\n",
       "           986,   690,    33,  1581,    14, 14913, 33844, 21303,  5298, 29210,\n",
       "         14526,   819,    11,   181,   417,  1484, 25606,   959,  2156,     7,\n",
       "          1248,  2156,   117,   892,    34,  2024,  1118,   181,   417,  1484,\n",
       "            19,     8,   396,  6882,     7, 10154,     5,   913,     9,  6882,\n",
       "            15, 14526, 29210,  2963,    11,   181,   417,   479,  1437, 50118,\n",
       "            42,   892,  1118, 14526,   819,   420,   654,   181,   417,  3597,\n",
       "            19,     8,   396,  6882,    36,   601,   181,  6106,  2744, 25606,\n",
       "          2357,   181,  6106,  4839,  2156,    54, 12796, 27548,     8, 14913,\n",
       "         33844,  9779,  4990,   479,  1437, 50118,   333,   819,    21,  1118,\n",
       "           420,     5,   511, 14526, 30700,  4832,  2007,  1503,  1589, 17737,\n",
       "           257,  1075, 33523,  5774,  2078,  2156,  1031,  5043,    36,   364,\n",
       "             4,   571,     4,  2156,   278,   111,  9255,  4839,  2156,   447,\n",
       "          3783,  2156,  2777,  2156,     8,  3783,  1589,    92, 14580,  2239,\n",
       "           479,  1437, 50118,   775,   969,    14,   181,  6106,  2744,  3744,\n",
       "          3625,  3007,    15,     5, 16808,  8968,   556,     8, 18173,  1296,\n",
       "             8,   233,   741,     9,     5,  5592,   442,  3685,    36,   326,\n",
       "         16100,   111,   741,  4839,  1118,     7,     5,   181,  6106,   333,\n",
       "           479,  1437, 50118,    89,    58,   117,   333,  5550,    11, 14580,\n",
       "          6626,  6761,  2156, 16437,  3783,  2156,    50,   326, 16100,   111,\n",
       "            10,   819,   479,    11,  6427,  2156,  1437, 50118,  6882,    11,\n",
       "           181,   417,    34,    10, 31087,   913,    15,   447,  3783,     8,\n",
       "          1503,   337,   278,   111,  9255,   479,     2]),\n",
       " 'noised': tensor([    0,  6762,    15,     5,  8819,     9,  6882,    11,  2221,  9554,\n",
       "           128,    29,  2199,    36,   181,   417,  4839,    34,    57, 20428,\n",
       "          1135,    63, 21087,    11,   823,   654,   207,     9,  1484,     8,\n",
       "            63,  2430,   913,    15,  1318,     9,   301,   479,  1437, 50118,\n",
       "           986,   690,    33,  1581,    14, 14913, 33844, 21303,  5298, 29210,\n",
       "         14526,   819,    11,   181,   417,  1484, 25606,   959,  2156,     7,\n",
       "          1248,  2156,   117,   892,    34,  2024,  1118,   181,   417,  1484,\n",
       "            19,     8,   396,  6882,     7, 10154,     5,   913,     9,  6882,\n",
       "            15, 14526, 29210,  2963,    11,   181,   417,   479,  1437, 50118,\n",
       "            42,   892,  1118, 14526,   819,   420,   654,   181,   417,  3597,\n",
       "            19,     8,   396,  6882,    36,   601,   181,  6106,  2744, 25606,\n",
       "          2357,   181,  6106,  4839,  2156,    54, 12796, 27548,     8, 14913,\n",
       "         33844,  9779,  4990,   479,  1437, 50118,   333,   819,    21,  1118,\n",
       "           420,     5,   511, 14526, 30700,  4832,  2007,  1503,  1589, 17737,\n",
       "           257,  1075, 33523,  5774,  2078,  2156,  1031,  5043,    36,   364,\n",
       "             4,   571,     4,  2156,   278,   111,  9255,  4839,  2156,   447,\n",
       "          3783,  2156,  2777,  2156,     8,  3783,  1589,    92, 14580,  2239,\n",
       "           479,  1437, 50118,   775,   969,    14,   181,  6106,  2744,  3744,\n",
       "          3625,  3007,    15,     5, 16808,  8968,   556,     8, 18173,  1296,\n",
       "             8,   233,   741,     9,     5,  5592,   442,  3685,    36,   326,\n",
       "         16100,   111,   741,  4839,  1118,     7,     5,   181,  6106,   333,\n",
       "           479,  1437, 50118,    89,    58,   117,   333,  5550,    11, 14580,\n",
       "          6626,  6761,  2156, 16437,  3783,  2156,    50,   326, 16100,   111,\n",
       "            10,   819,   479,    11,  6427,  2156,  1437, 50118,  6882,    11,\n",
       "           181,   417,    34,    10, 31087,   913,    15,   447,  3783,     8,\n",
       "          1503,   337,   278,   111,  9255,   479,  4974, 35872, 39531,  4974,\n",
       "         35872, 39531,  4974, 35872, 39531,     2])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118681/118681 [00:06<00:00, 18876.52it/s]\n",
      "100%|██████████| 6573/6573 [00:00<00:00, 25194.53it/s]\n"
     ]
    }
   ],
   "source": [
    "aug(\"pubmed\", \"train\")\n",
    "aug(\"pubmed\", \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5699/5699 [00:00<00:00, 25137.17it/s]\n",
      "100%|██████████| 5677/5677 [00:00<00:00, 25058.79it/s]\n"
     ]
    }
   ],
   "source": [
    "aug(\"arxiv\", \"test\")\n",
    "aug(\"arxiv\", \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174216/174216 [00:11<00:00, 15402.70it/s]\n"
     ]
    }
   ],
   "source": [
    "aug(\"arxiv\", \"train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hg",
   "language": "python",
   "name": "hg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
