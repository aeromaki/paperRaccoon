{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "z6QKf3fJKdqb"
   },
   "source": [
    "## [0] Import\n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "a-e0YyXaKN3F"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers datasets beartype --upgrade accelerate numba nvidia-ml-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pmy71DZqKAV6",
    "outputId": "06d6f0c1-50c9-4c6e-cba6-e05eea7cea64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code is written at 2023-06-22 21:00:24.852697\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import pickle\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# Model Save & Load\n",
    "import os\n",
    "# GPU Reset\n",
    "from numba import cuda\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "# from torchsummary import summary\n",
    "\n",
    "# 모델, Tokenizer Load\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer, LEDForConditionalGeneration, LEDModel, LEDTokenizer, BartModel, LEDConfig\n",
    "\n",
    "# 데이터셋 Load from Summarize_from_feedvback, Huggingface\n",
    "from datasets import load_dataset\n",
    "\n",
    "# RL Training\n",
    "from beartype.typing import Deque, Tuple, List\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "\n",
    "print(\"This code is written at \" + str(datetime.datetime.now()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wnh3ev-ebYIr"
   },
   "source": [
    "#### GPU Reset & Setting device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nyWlZQiFbYIr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef GPU_reset():\\n    device = cuda.get_current_device()\\n    device.reset\\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\\n    print(device)\\n\\n    return device\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def GPU_reset():\n",
    "    device = cuda.get_current_device()\n",
    "    device.reset\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    print(device)\n",
    "\n",
    "    return device\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GJdLAcRSbYIs",
    "outputId": "d464e2bf-59a0-43ca-d911-a2550f130316"
   },
   "outputs": [],
   "source": [
    "#device = GPU_reset()\n",
    "\n",
    "device0 = \"cuda:0\"\n",
    "device1 = \"cuda:1\"\n",
    "device2 = \"cuda:2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GmkUXRp6bYIs",
    "outputId": "d3563ebb-2b31-4cd8-e81d-9ab880f55631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 22 21:00:25 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    45W / 300W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    46W / 300W |      0MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WJNepFdhbYIs"
   },
   "source": [
    "## [*] Hyper Parameter Setting\n",
    "\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VH3CitzkbYIs"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "EPOCH = 1\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UmEZqNefTo1q"
   },
   "source": [
    "## [1] Tokenizer\n",
    "- Longformer의 Tokenizer 정의\n",
    "- Global Attention Mask 함수 정의\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MPg82SooTrPb"
   },
   "outputs": [],
   "source": [
    "from transformers import LEDTokenizer\n",
    "tokenizer = LEDTokenizer.from_pretrained(\"allenai/led-large-16384-arxiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gdaaMVQZbYIt"
   },
   "outputs": [],
   "source": [
    "def generate_global_attention_mask(tokenizer, input_ids):\n",
    "    mask = torch.torch.zeros_like(input_ids)\n",
    "    mask[((input_ids == tokenizer.bos_token_id) | (input_ids == tokenizer.eos_token_id)).nonzero(as_tuple=True)] = 1\n",
    "    return mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rM_Q7hSFR9QJ"
   },
   "source": [
    "## [2] DataLoad\n",
    "- 데이터 Load\n",
    "- 데이터 전처리\n",
    "- 데이터 Loader\n",
    "\n",
    "---------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BPpvZNh_tCyF"
   },
   "source": [
    "### [2.1] Data Preprocessing\n",
    "\n",
    "- Human Feedback 데이터 Dictionary를 Dataframe으로 변환\n",
    "- 알맞은 문장 추출\n",
    "- DataLoader 생성"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7fyouZjybYIt"
   },
   "source": [
    "#### Text DataFrame 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87,
     "referenced_widgets": [
      "d62e55e7919340fbac4b5306318be0f2",
      "fbaefe5beb4a4881bb491545a730b652",
      "bcaab85650bc4a66a347714e10469aef",
      "6db1a3f7785e41c0bd3a97cdc3d0af93",
      "f75fb556375c45f5bc02f66b3b8c7372",
      "1629ebaef4074795863457ecff11c048",
      "dc1f14103205437ab7ac513906c61f8d",
      "10ad05244ea645108a724a56f7419ba3",
      "1420735f82574467a0ba3e8ecaed4b43",
      "1c4cba28480447029e01d90fcf9b185d",
      "3c0db56612c94787b5f5fccd74f394df"
     ]
    },
    "id": "5JPmUvJLbYIt",
    "outputId": "84c81c6a-53b5-4d49-f2a8-87f9bc496515"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: arxiv-summarization/section\n",
      "Found cached dataset arxiv-summarization (/root/.cache/huggingface/datasets/ccdv___arxiv-summarization/section/1.0.0/fa2c9abf4312afb8660ef8e041d576b8e3943ea96ae771bd3cd091b5798e7cc3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8204d62061e9451e9a26de08f83ed30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "class Data_Preprocessing\n",
    "    - HuggingFace의 Summarize from feedback 전용 데이터 전처리 Class\n",
    "    - Train 데이터와 Validation 데이터 출력\n",
    "'''\n",
    "\n",
    "class Data_Preprocessing:\n",
    "    def __init__(self):\n",
    "        # DownLoad Data from huggingFace\n",
    "        ## Text Summary 데이터\n",
    "        ## CNN, TL;DR, Daily Mail\n",
    "        self.data_feedback = load_dataset(\"ccdv/arxiv-summarization\")\n",
    "\n",
    "        # Split into Train and Validation dataset\n",
    "        # Convert to DataFrame\n",
    "        self.df_train = pd.DataFrame(self.data_feedback['train'])\n",
    "        self.df_valid = pd.DataFrame(self.data_feedback['validation'])\n",
    "\n",
    "\n",
    "    # Original Text + Summarized Text 데이터 Columm 추출\n",
    "    def Data_cleaning(self, df):\n",
    "        df['original_text'] = df['article']\n",
    "        # df_valid['original_text'] = self.df_valid['article']\n",
    "\n",
    "        # df_train['sum_text'] = [row['text'] for row in df_train['summary']]\n",
    "        # df_valid['sum_text'] = [row['text'] for row in df_valid['summary']]\n",
    "\n",
    "        # df_all = pd.concat([df_train[['original_text', 'sum_text']], df_valid[['original_text', 'sum_text']]], ignore_index=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    # 최종 DataFrame 출력\n",
    "    def data_complete_form(self):\n",
    "        df_train = self.Data_cleaning(self.df_train)\n",
    "        df_valid = self.Data_cleaning(self.df_valid)\n",
    "\n",
    "        return df_train, df_valid\n",
    "\n",
    "# 실행 코드\n",
    "df_train, df_valid = Data_Preprocessing().data_complete_form()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "qcIb0__EbYIu",
    "outputId": "19baeed5-c74f-4350-c162-7302ad291f0b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>abstract</th>\n",
       "      <th>original_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>additive models @xcite provide an important fa...</td>\n",
       "      <td>additive models play an important role in semi...</td>\n",
       "      <td>additive models @xcite provide an important fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the leptonic decays of a charged pseudoscalar ...</td>\n",
       "      <td>we have studied the leptonic decay @xmath0 , v...</td>\n",
       "      <td>the leptonic decays of a charged pseudoscalar ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  additive models @xcite provide an important fa...   \n",
       "1  the leptonic decays of a charged pseudoscalar ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  additive models play an important role in semi...   \n",
       "1  we have studied the leptonic decay @xmath0 , v...   \n",
       "\n",
       "                                       original_text  \n",
       "0  additive models @xcite provide an important fa...  \n",
       "1  the leptonic decays of a charged pseudoscalar ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HlHf_VkpBQVl"
   },
   "source": [
    "### [2.2] DataLoader\n",
    "- 원본 Text와 Summarize가 합쳐진 데이터 형식의 DataFrame을 DataLoader로 처리\n",
    "- 입력: DataFrame <br>\n",
    "- Feature : original_with_good_sum,   original_with_bad_sum  </br>\n",
    "- 내용: 원본 텍스트 + 긍정 Summary, 원본 텍스트 + 부정 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0hOtsGPxbYIu"
   },
   "outputs": [],
   "source": [
    "class RL_Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df_textsum): #, transforms_=None, random_masking = False,  unaligned=True ):\n",
    "\n",
    "        self.original_text = df_textsum['original_text']\n",
    "        # self.sum_text = df_textsum['sum_text']\n",
    "        # self.old_action = df_textsum['old_action_prob']\n",
    "\n",
    "        print(f\"My_dataset __init__ received : {self.original_text.shape}\") # , {self.old_action.shape}\")\n",
    "        print(f\"Data Type : {type(self.original_text[0])}\") #, type(self.old_action[0])}\")\n",
    "        # print(f\"Data example : {self.original_text[0]}\") # , {self.sum_text[0]}}\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        original_text = self.original_text[index]\n",
    "        # sum_text = self.sum_text[index]\n",
    "        # old_action_prob = self.old_action[index]\n",
    "\n",
    "        return original_text # , sum_text# old_action_prob\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "Jb4x-rNntsac",
    "outputId": "9e69d8ce-6a42-4413-fd2a-a4fd36b45504"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>abstract</th>\n",
       "      <th>original_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>additive models @xcite provide an important fa...</td>\n",
       "      <td>additive models play an important role in semi...</td>\n",
       "      <td>additive models @xcite provide an important fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the leptonic decays of a charged pseudoscalar ...</td>\n",
       "      <td>we have studied the leptonic decay @xmath0 , v...</td>\n",
       "      <td>the leptonic decays of a charged pseudoscalar ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  additive models @xcite provide an important fa...   \n",
       "1  the leptonic decays of a charged pseudoscalar ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  additive models play an important role in semi...   \n",
       "1  we have studied the leptonic decay @xmath0 , v...   \n",
       "\n",
       "                                       original_text  \n",
       "0  additive models @xcite provide an important fa...  \n",
       "1  the leptonic decays of a charged pseudoscalar ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0EPJBx-iwRnb",
    "outputId": "fbf39dfc-efc9-434e-b56f-8c85150e5d10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================\n",
      "\n",
      "TRAIN LOADER\n",
      "My_dataset __init__ received : (203037,)\n",
      "Data Type : <class 'str'>\n",
      "\n",
      "====================================================================\n",
      "\n",
      "VALID LOADER\n",
      "My_dataset __init__ received : (6436,)\n",
      "Data Type : <class 'str'>\n",
      "\n",
      "====================================================================\n"
     ]
    }
   ],
   "source": [
    "print('====================================================================')\n",
    "print('')\n",
    "print(\"TRAIN LOADER\")\n",
    "train_loader = torch.utils.data.DataLoader(RL_Dataset(df_train), batch_size=BATCH_SIZE, shuffle=False, drop_last = False)\n",
    "print('')\n",
    "print(\"====================================================================\")\n",
    "print('')\n",
    "print(\"VALID LOADER\")\n",
    "valid_loader = torch.utils.data.DataLoader(RL_Dataset(df_valid), batch_size=BATCH_SIZE, shuffle=False, drop_last = False)\n",
    "print('')\n",
    "print(\"====================================================================\")\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(RL_Dataset(df_test), batch_size=BATCH_SIZE, shuffle=False, drop_last = False)\n",
    "# print('')\n",
    "# print(\"====================================================================\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aE3wu4NXKhoG"
   },
   "source": [
    "## [3] Model\n",
    "- Policy model : LED For Conditional Generation\n",
    "- Input : (token, global_attention_mask) type: tensor\n",
    "-------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WV1N8qY4eqGW"
   },
   "source": [
    "### [3.1] Policy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "c9d1ff9d84cb4e1796efbd2f0bd42631",
      "d3d3523f49264b67bac2e33343e2a4fa",
      "3b7abaa2b8694aa7ac419804cdb5e4b5",
      "074de416985c4ef78b604475090707d9",
      "b4fc0bf4148f4cab93e93f31c9e40c78",
      "1bd9297e098f4b2b98526cfb725b013c",
      "ba78a17515964f20939dffe238ece146",
      "381041138c1643b390a0d379b3455ac5",
      "c7cb709c9a734725a25c74d3217754ae",
      "38fb4e1d2f51411e86c41dfb8d18d5db",
      "a183e0e9981a4ded8db6530bcf99912a",
      "4923c169d9d84346800d71df46675083",
      "90bd4b70b3044893a7412126b3dcb166",
      "41272565bee54a8facfea11bdfa41aa2",
      "a8f7be576e6a4d46bee62d065deee79e",
      "021c6095623147418625c3b0b80f27ba",
      "fa048943056948fe8f31bdcceadde9b6",
      "12b28ffa15824e7f91f743c54167fa31",
      "e0c3093b53c1432c9eacb24770355429",
      "1e5191d117f742f5b2a4151df3101fc0",
      "9fe36dadd26c4ac9919354bb4e2b4a99",
      "c23c666a408e4e9ba8de7267d2e0dad8"
     ]
    },
    "id": "2OyG779wbYIv",
    "outputId": "12c4d062-de6c-46b3-d5af-4aeb4400d389"
   },
   "outputs": [],
   "source": [
    "# policy_model = LEDForConditionalGeneration.from_pretrained(\"allenai/led-large-16384-arxiv\").to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Jscs34iGet_P"
   },
   "source": [
    "### [3.2] Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "smcQdlzreys8"
   },
   "outputs": [],
   "source": [
    "class RewardModel(nn.Module):\n",
    "    def __init__(self, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.led = AutoModel.from_config(AutoConfig.from_pretrained(\"allenai/led-large-16384-arxiv\")).get_encoder()\n",
    "        self.bart = AutoModel.from_config(AutoConfig.from_pretrained(\"facebook/bart-large\")).get_encoder()\n",
    "\n",
    "        self.flatten = nn.Linear(1024, 1)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(17408, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, summary_input_ids, global_attention_mask=None):\n",
    "        hidden_state = self.led(input_ids, global_attention_mask=global_attention_mask).last_hidden_state\n",
    "        with torch.no_grad():\n",
    "            output = torch.zeros((hidden_state.shape[0], 16384, 1024)).to(self.device) # head가 fixed size만 받을 수 있으므로 0으로 padding\n",
    "            output[:, :hidden_state.shape[1], :] = hidden_state\n",
    "\n",
    "        bart_hidden_state = self.bart(summary_input_ids).last_hidden_state\n",
    "        bart_output = torch.zeros((bart_hidden_state.shape[0], 1024, 1024)).to(self.device) # head가 fixed size만 받을 수 있으므로 0으로 padding\n",
    "        bart_output[:, :bart_hidden_state.shape[1], :] = bart_hidden_state\n",
    "\n",
    "        concat = torch.cat([output.repeat((summary_input_ids.shape[0], 1, 1)), bart_output], dim=1)\n",
    "        concat = self.flatten(concat)\n",
    "        result = self.head(concat.transpose(1, 2))\n",
    "\n",
    "        return result.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155,
     "referenced_widgets": [
      "dbba4433df5648cb80594be695954954",
      "c254524bd00d458ab44746b4c41dcb40",
      "7a16bc6d41f946c68d830bc90a184c49",
      "13c7353e6f3b4ccfad60e832be00121b",
      "640d74c65d724110ac417f8fbab76a37",
      "1780de432ade4f61a2086907bc96a4fe",
      "9069993d722e4714a1880288bb08e790",
      "5bc6456f991d4eecb92a228104fec11b",
      "d8e4cf285be145b788354f9313418d00",
      "cc90d1e7943e4d72b33e558e8b1ad1b6",
      "23d6665f672f482cbe9c7ff50799aec3",
      "adfb3407896741e0b77286cdc1183011",
      "a0981cbfcc714b9cb1ef692ae98c6ade",
      "8ad2d66a2bad4716bad46f8f3be4f24f",
      "faf53257661e4cc4a8b6ecdefc61027a",
      "905f2b91fdbd4416a4aaf5d958831951",
      "66916ec7aa7f4587a88cb8880967d7d2",
      "3b4f9d4f51bd406e97f721ec9584f60b",
      "ab2c791edad745c8ac03cb80bc924161",
      "af221a6a4d4149c2be9510a5d6a6b026",
      "458f1a29aeee47418454de8d96a81c04",
      "926598e17eff4e1f986b8f26d140faca"
     ]
    },
    "id": "Dw9bv0W9fAjC",
    "outputId": "0d736899-6fbc-469c-ee5e-d3b24665f010"
   },
   "outputs": [],
   "source": [
    "# reward_model = RewardModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_info(_model, _version=\"ver_1\"):\n",
    "    if not os.path.isdir(\"./RL_policy_model\"):\n",
    "        os.makedirs(\"./RL_policy_model\")\n",
    "    # 모델 정보 저장\n",
    "    _model = _model.cpu()\n",
    "    torch.save({'model_state_dict': _model.state_dict(),\n",
    "                # 'optimizer_state_dict': _optimizer.state_dict(),\n",
    "                # 'record_list' : {'train_loss': _train_loss, 'valid_loss': _valid_loss},\n",
    "                }, f\"./policy_model/RL_policy_model_{_version}.pth\")  #policy_model_ver_1\n",
    "\n",
    "    print(f\"******************* Model Saved : RL_policy_model_{_version} *******************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef load_model_info(_file_path):\\n    \"\"\"\\n    if not os.path.exists(_file_path):\\n        print(\"FATAL ERROR : model path not exist\")\\n    model_info = torch.load(_file_path)\\n    print(f\"******************* model_loaded FROM {_file_path} *******************\")\\n    \"\"\"\\n    config = LEDConfig.from_pretrained(\"allenai/led-large-16384-arxiv\")\\n    model = LEDForConditionalGeneration(config)\\n\\n    #model.load_state_dict(model_info[\\'model_state_dict\\'])\\n    model.to(device)\\n    model.eval()\\n\\n    return model\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def load_model_info(_file_path):\n",
    "    \"\"\"\n",
    "    if not os.path.exists(_file_path):\n",
    "        print(\"FATAL ERROR : model path not exist\")\n",
    "    model_info = torch.load(_file_path)\n",
    "    print(f\"******************* model_loaded FROM {_file_path} *******************\")\n",
    "    \"\"\"\n",
    "    config = LEDConfig.from_pretrained(\"allenai/led-large-16384-arxiv\")\n",
    "    model = LEDForConditionalGeneration(config)\n",
    "\n",
    "    #model.load_state_dict(model_info['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LEDConfig.from_pretrained(\"allenai/led-large-16384-arxiv\")\n",
    "\n",
    "old_policy_model = LEDForConditionalGeneration(config)\n",
    "new_policy_model = LEDForConditionalGeneration(config)#LEDForConditionalGeneration.from_pretrained(\"allenai/led-large-16384-arxiv\")\n",
    "\n",
    "# old_policy_model = LEDForConditionalGeneration.from_pretrained(\"allenai/led-large-16384-arxiv\").to(device)\n",
    "# new_policy_model = LEDForConditionalGeneration.from_pretrained(\"allenai/led-large-16384-arxiv\").to(device)\n",
    "\n",
    "reward_model = RewardModel(device2)\n",
    "#reward_model.load_state_dict(torch.load(\"reward_model_openai_2190.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old_policy_model = nn.DataParallel(old_policy_model,  device_ids = [0,1])\n",
    "#new_policy_model = nn.DataParallel(new_policy_model,  device_ids = [0,1])\n",
    "#reward_model = nn.DataParallel(reward_model,  device_ids = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_policy_model = old_policy_model.to(device0)\n",
    "new_policy_model = new_policy_model.to(device1)\n",
    "reward_model = reward_model.to(device2)\n",
    "\n",
    "# old_policy_model = old_policy_model.to(device)\n",
    "# new_policy_model = new_policy_model.to(device)\n",
    "# reward_model = reward_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0), device(type='cuda', index=1), 'cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_policy_model.device, new_policy_model.device, reward_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 22 21:01:05 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    63W / 300W |   4365MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    65W / 300W |   2323MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cVGMzKLaPQme"
   },
   "source": [
    "## [4] Reinforcement Learning Training\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvidia_smi\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "nvidia_smi.nvmlInit()\n",
    "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "966-T0wsTFMt"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(new_policy_model.parameters(), lr=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: arxiv-summarization/section\n",
      "Found cached dataset arxiv-summarization (/root/.cache/huggingface/datasets/ccdv___arxiv-summarization/section/1.0.0/fa2c9abf4312afb8660ef8e041d576b8e3943ea96ae771bd3cd091b5798e7cc3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ec2e80dc7749638d2a565a9fd37f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ccdv/arxiv-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wRTR6nO8rmIZ",
    "outputId": "0e7f29a8-582a-477e-9e6d-caa93ffda92a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,  4917, 15589,  3092,   787]])\n",
      "cpu torch.Size([1, 6791])\n",
      "1. START/Thu Jun 22 21:01:12 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    66W / 300W |   4365MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    65W / 300W |   2323MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 6791]) torch.Size([1, 1000]) torch.Size([1, 6791])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:2919: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 ON/LOSS :  0.03374732285737991\n",
      "tensor([[    0,   627,  2084,  3320, 10003]])\n",
      "cpu torch.Size([1, 4830])\n",
      "1. START/Thu Jun 22 21:01:17 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    64W / 300W |  28351MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    66W / 300W |  37997MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 4830]) torch.Size([1, 1000]) torch.Size([1, 4830])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  0.04039845988154411\n",
      "tensor([[   0,  627, 4240, 3611,    9]])\n",
      "cpu torch.Size([1, 6881])\n",
      "1. START/Thu Jun 22 21:01:21 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    65W / 300W |  28351MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    70W / 300W |  37997MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 6881]) torch.Size([1, 1000]) torch.Size([1, 6881])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  0.037328947335481644\n",
      "tensor([[    0, 26302,   918,     9, 13443]])\n",
      "cpu torch.Size([1, 5360])\n",
      "1. START/Thu Jun 22 21:01:24 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    64W / 300W |  29635MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    67W / 300W |  42203MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 5360]) torch.Size([1, 1000]) torch.Size([1, 5360])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  0.03795252740383148\n",
      "tensor([[  0, 627,  98, 111, 373]])\n",
      "cpu torch.Size([1, 14272])\n",
      "1. START/Thu Jun 22 21:01:28 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    67W / 300W |  29635MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    68W / 300W |  42203MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 14272]) torch.Size([1, 1000]) torch.Size([1, 14272])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  0.02789124846458435\n",
      "tensor([[    0,  2716,   787,  1178, 40051]])\n",
      "cpu torch.Size([1, 11590])\n",
      "1. START/Thu Jun 22 21:01:34 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    65W / 300W |  65025MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    69W / 300W |  81079MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 11590]) torch.Size([1, 1000]) torch.Size([1, 11590])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  0.03207924962043762\n",
      "tensor([[    0,   627, 31016,    52,  2268]])\n",
      "cpu torch.Size([1, 4659])\n",
      "1. START/Thu Jun 22 21:01:39 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    67W / 300W |  65025MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    71W / 300W |  81079MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 4659]) torch.Size([1, 1000]) torch.Size([1, 4659])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  0.03930078074336052\n",
      "tensor([[   0, 5632, 1233,  557, 1170]])\n",
      "cpu torch.Size([1, 4518])\n",
      "1. START/Thu Jun 22 21:01:43 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    64W / 300W |  65025MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    71W / 300W |  81093MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 4518]) torch.Size([1, 1000]) torch.Size([1, 4518])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  0.03673609718680382\n",
      "tensor([[   0,  627, 2835, 1258,  609]])\n",
      "cpu torch.Size([1, 2348])\n",
      "1. START/Thu Jun 22 21:01:46 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    64W / 300W |  65025MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    74W / 300W |  81093MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 2348]) torch.Size([1, 1000]) torch.Size([1, 2348])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  0.03885248303413391\n",
      "tensor([[   0, 1264, 6167,  898,   14]])\n",
      "cpu torch.Size([1, 9806])\n",
      "1. START/Thu Jun 22 21:01:49 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    68W / 300W |  65025MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    71W / 300W |  81093MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 9806]) torch.Size([1, 1000]) torch.Size([1, 9806])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (21321 > 16384). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 ON/LOSS :  0.03502907603979111\n",
      "tensor([[    0,  5605,  9779, 26683,  1635]])\n",
      "tensor([[    0, 26302,   918,     9, 16426]])\n",
      "cpu torch.Size([1, 2919])\n",
      "1. START/Thu Jun 22 21:01:53 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    68W / 300W |  65025MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    72W / 300W |  81093MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 2919]) torch.Size([1, 1000]) torch.Size([1, 2919])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  0.03521513566374779\n",
      "tensor([[    0, 39064,   783,   111, 12418]])\n",
      "tensor([[    0, 26941,     8,   741,  3876]])\n",
      "cpu torch.Size([1, 4444])\n",
      "1. START/Thu Jun 22 21:01:56 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    65W / 300W |  65025MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    74W / 300W |  81093MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 4444]) torch.Size([1, 1000]) torch.Size([1, 4444])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  0.03902087360620499\n",
      "tensor([[   0,  627,  892,    9, 2422]])\n",
      "cpu torch.Size([1, 14672])\n",
      "1. START/Thu Jun 22 21:02:00 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    67W / 300W |  65025MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    72W / 300W |  81093MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 14672]) torch.Size([1, 1000]) torch.Size([1, 14672])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  0.04466119036078453\n",
      "tensor([[    0,   627,    86, 15958, 23427]])\n",
      "cpu torch.Size([1, 5637])\n",
      "1. START/Thu Jun 22 21:02:06 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    65W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    73W / 300W |  74021MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 5637]) torch.Size([1, 1000]) torch.Size([1, 5637])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  0.03683768957853317\n",
      "tensor([[    0, 34645,   405,  1790,    11]])\n",
      "cpu torch.Size([1, 6046])\n",
      "1. START/Thu Jun 22 21:02:10 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    65W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    77W / 300W |  74039MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 6046]) torch.Size([1, 1000]) torch.Size([1, 6046])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  0.032456666231155396\n",
      "tensor([[    0,   179, 18613, 20181,  3435]])\n",
      "cpu torch.Size([1, 13190])\n",
      "1. START/Thu Jun 22 21:02:14 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    67W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   49C    P0    77W / 300W |  74039MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 13190]) torch.Size([1, 1000]) torch.Size([1, 13190])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  0.0419173464179039\n",
      "tensor([[    0,  1990,  4460, 49074,   787]])\n",
      "cpu torch.Size([1, 980])\n",
      "1. START/Thu Jun 22 21:02:19 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    69W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   50C    P0    74W / 300W |  74039MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 980]) torch.Size([1, 980]) torch.Size([1, 980])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(0, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  0.03768777847290039\n",
      "tensor([[    0,   627,  2084,   642, 15491]])\n",
      "cpu torch.Size([1, 12483])\n",
      "1. START/Thu Jun 22 21:02:21 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    65W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   49C    P0    78W / 300W |  74047MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 12483]) torch.Size([1, 1000]) torch.Size([1, 12483])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(47037, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  nan\n",
      "tensor([[  0, 405,  16, 157, 684]])\n",
      "cpu torch.Size([1, 7005])\n",
      "1. START/Thu Jun 22 21:02:27 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    68W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   51C    P0    77W / 300W |  74047MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 7005]) torch.Size([1, 1000]) torch.Size([1, 7005])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(47037, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  nan\n",
      "tensor([[    0,   102, 11259,  1804,  1498]])\n",
      "cpu torch.Size([1, 1792])\n",
      "1. START/Thu Jun 22 21:02:31 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    65W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   51C    P0    78W / 300W |  74047MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 1792]) torch.Size([1, 1000]) torch.Size([1, 1792])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(47037, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  nan\n",
      "tensor([[    0,   179, 23778,   821,     4]])\n",
      "cpu torch.Size([1, 9580])\n",
      "1. START/Thu Jun 22 21:02:33 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    65W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   51C    P0    75W / 300W |  74047MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 9580]) torch.Size([1, 1000]) torch.Size([1, 9580])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(47037, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  nan\n",
      "tensor([[    0,   627, 43660,     9,   769]])\n",
      "cpu torch.Size([1, 12201])\n",
      "1. START/Thu Jun 22 21:02:38 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    65W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   51C    P0    76W / 300W |  74047MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 12201]) torch.Size([1, 1000]) torch.Size([1, 12201])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(47037, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  nan\n",
      "tensor([[    0, 24701,  1512,  3277,    32]])\n",
      "cpu torch.Size([1, 5248])\n",
      "1. START/Thu Jun 22 21:02:43 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    65W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   52C    P0    76W / 300W |  74047MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 5248]) torch.Size([1, 1000]) torch.Size([1, 5248])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(47037, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  nan\n",
      "tensor([[   0,  405,   16, 2047,   14]])\n",
      "cpu torch.Size([1, 13083])\n",
      "1. START/Thu Jun 22 21:02:47 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    69W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   52C    P0    77W / 300W |  74047MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 13083]) torch.Size([1, 1000]) torch.Size([1, 13083])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(47037, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  nan\n",
      "tensor([[    0,   627,   595, 15864,  2156]])\n",
      "cpu torch.Size([1, 10432])\n",
      "1. START/Thu Jun 22 21:02:53 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    66W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   53C    P0    80W / 300W |  74047MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 10432]) torch.Size([1, 1000]) torch.Size([1, 10432])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(47037, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  nan\n",
      "tensor([[    0, 34335,  2963,    32,   855]])\n",
      "cpu torch.Size([1, 8258])\n",
      "1. START/Thu Jun 22 21:02:58 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    67W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   53C    P0    77W / 300W |  74047MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 8258]) torch.Size([1, 1000]) torch.Size([1, 8258])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(47037, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  nan\n",
      "tensor([[    0,   179, 17997,   335,  5774]])\n",
      "cpu torch.Size([1, 3743])\n",
      "1. START/Thu Jun 22 21:03:02 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    66W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   53C    P0    77W / 300W |  74047MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 3743]) torch.Size([1, 1000]) torch.Size([1, 3743])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(47037, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  nan\n",
      "tensor([[  0, 405,  34, 555,  10]])\n",
      "cpu torch.Size([1, 9261])\n",
      "1. START/Thu Jun 22 21:03:05 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    66W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   53C    P0    80W / 300W |  74047MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 9261]) torch.Size([1, 1000]) torch.Size([1, 9261])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(47037, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  nan\n",
      "tensor([[   0, 1264,    9,    5, 6451]])\n",
      "cpu torch.Size([1, 11408])\n",
      "1. START/Thu Jun 22 21:03:10 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    67W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   54C    P0    81W / 300W |  74047MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 11408]) torch.Size([1, 1000]) torch.Size([1, 11408])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(47037, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  nan\n",
      "tensor([[    0, 35901,   268, 46246, 21262]])\n",
      "cpu torch.Size([1, 6620])\n",
      "1. START/Thu Jun 22 21:03:15 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    67W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   54C    P0    77W / 300W |  74047MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 6620]) torch.Size([1, 1000]) torch.Size([1, 6620])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(47037, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  nan\n",
      "tensor([[   0,  627, 9813,  111, 6381]])\n",
      "cpu torch.Size([1, 8819])\n",
      "1. START/Thu Jun 22 21:03:19 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.56.06    Driver Version: 520.56.06    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100 80G...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    66W / 300W |  75755MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100 80G...  On   | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   54C    P0    80W / 300W |  74047MiB / 81920MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "2. ON/3 ON/4 ON/5 ON/6 ON\n",
      "torch.Size([1, 8819]) torch.Size([1, 1000]) torch.Size([1, 8819])\n",
      "6 ON\n",
      "tensor(50118, device='cuda:0') tensor(47037, device='cuda:0') tensor(1, device='cuda:0')\n",
      "8 ON/9 ON/10 ON/11 ON/LOSS :  nan\n",
      "tensor([[    0,  3530,  2231, 32426,  2192]])\n",
      "cpu torch.Size([1, 5104])\n",
      "1. START/"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'child' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/utils/_process_posix.py:148\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 148\u001b[0m     child \u001b[38;5;241m=\u001b[39m \u001b[43mpexpect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-c\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Vanilla Pexpect\u001b[39;00m\n\u001b[1;32m    149\u001b[0m flush \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pexpect/pty_spawn.py:205\u001b[0m, in \u001b[0;36mspawn.__init__\u001b[0;34m(self, command, args, timeout, maxread, searchwindowsize, logfile, cwd, env, ignore_sighup, echo, preexec_fn, encoding, codec_errors, dimensions, use_poll)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimensions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_poll \u001b[38;5;241m=\u001b[39m use_poll\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pexpect/pty_spawn.py:303\u001b[0m, in \u001b[0;36mspawn._spawn\u001b[0;34m(self, command, args, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m [a \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m a\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding)\n\u001b[1;32m    301\u001b[0m                  \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptyproc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spawnpty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mptyproc\u001b[38;5;241m.\u001b[39mpid\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pexpect/pty_spawn.py:315\u001b[0m, in \u001b[0;36mspawn._spawnpty\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Spawn a pty and return an instance of PtyProcess.'''\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mptyprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPtyProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ptyprocess/ptyprocess.py:303\u001b[0m, in \u001b[0;36mPtyProcess.spawn\u001b[0;34m(cls, argv, cwd, env, echo, preexec_fn, dimensions, pass_fds)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# Parent\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m inst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# Set some informational attributes\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ptyprocess/ptyprocess.py:160\u001b[0m, in \u001b[0;36mPtyProcess.__init__\u001b[0;34m(self, pid, fd)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfd \u001b[38;5;241m=\u001b[39m fd\n\u001b[0;32m--> 160\u001b[0m readf \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m writef \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mopen(fd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, buffering\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 24\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# print(\"ORIGIN_TOKEN \", origin_token.size())\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# print(\"ORIGIN MASK \", origin_mask.size())\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print(f\" GPU: {100 * (1 - info.free / info.total)}% used\")\u001b[39;00m\n\u001b[1;32m     21\u001b[0m   \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Old Actor output\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. START\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnvidia-smi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m action_logits \u001b[38;5;241m=\u001b[39m new_policy_model(input_ids \u001b[38;5;241m=\u001b[39m origin_token\u001b[38;5;241m.\u001b[39mto(device1), decoder_input_ids \u001b[38;5;241m=\u001b[39m origin_token\u001b[38;5;241m.\u001b[39mto(device1)[:,:\u001b[38;5;241m1000\u001b[39m], global_attention_mask \u001b[38;5;241m=\u001b[39m origin_mask\u001b[38;5;241m.\u001b[39mto(device1))\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. ON\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py:649\u001b[0m, in \u001b[0;36mZMQInteractiveShell.system_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m system(cmd)\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_exit_code\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar_expand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/utils/_process_posix.py:164\u001b[0m, in \u001b[0;36mProcessHandler.system\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    159\u001b[0m         out_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(child\u001b[38;5;241m.\u001b[39mbefore)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# We need to send ^C to the process.  The ascii code for '^C' is 3\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# (the character is known as ETX for 'End of Text', see\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# curses.ascii.ETX).\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m     \u001b[43mchild\u001b[49m\u001b[38;5;241m.\u001b[39msendline(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# Read and print any more output the program might produce on its\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# way out.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'child' referenced before assignment"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "start_time = time.time()\n",
    "\n",
    "# device0 - old\n",
    "# device1 - new\n",
    "# device2 - reward\n",
    "\n",
    "new_policy_model.train()\n",
    "old_policy_model.eval()\n",
    "reward_model.eval()\n",
    "for index, origin in enumerate(dataset[\"train\"][\"article\"]):    \n",
    "  # Preparation\n",
    "  origin_token = tokenizer.batch_encode_plus([origin], padding=True, return_tensors='pt').input_ids\n",
    "  print(origin_token[:,:5])\n",
    "\n",
    "  if origin_token.shape[1] > 16000:\n",
    "      continue\n",
    "    \n",
    "  print(origin_token.device, origin_token.shape)\n",
    "  origin_mask = generate_global_attention_mask(tokenizer, origin_token)\n",
    "  # print(\"ORIGIN_TOKEN \", origin_token.size())\n",
    "  # print(\"ORIGIN MASK \", origin_mask.size())\n",
    "  # info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "  # print(f\" GPU: {100 * (1 - info.free / info.total)}% used\")\n",
    "    \n",
    "  # Old Actor output\n",
    "  print(\"1. START\", end=\"/\")\n",
    "  !nvidia-smi\n",
    "  action_logits = new_policy_model(input_ids = origin_token.to(device1), decoder_input_ids = origin_token.to(device1)[:,:1000], global_attention_mask = origin_mask.to(device1)).logits\n",
    "  print(\"2. ON\", end=\"/\")\n",
    "  action_prob = torch.softmax(action_logits, dim=-1).to(device0)\n",
    "    \n",
    "  print(\"3 ON\", end=\"/\")\n",
    "  # Actor output\n",
    "  with torch.no_grad():\n",
    "      old_action_logits = old_policy_model(input_ids = origin_token.to(device0), decoder_input_ids = origin_token.to(device0)[:,:1000], global_attention_mask = origin_mask.to(device0)).logits\n",
    "  print(\"4 ON\", end=\"/\")\n",
    "  old_action_prob = torch.softmax(old_action_logits, dim=-1)\n",
    "\n",
    "    \n",
    "  print(\"5 ON\", end=\"/\")\n",
    "  sum_token = torch.argmax(action_prob, dim=-1 ).cpu()\n",
    "\n",
    "    \n",
    "  print(\"6 ON\")  \n",
    "  print(origin_token.shape, sum_token.shape, origin_mask.shape)\n",
    "  print(\"6 ON\")  \n",
    "  print(torch.max(origin_token), torch.max(sum_token), torch.max(origin_mask))\n",
    "  reward = reward_model(origin_token.to(device2), sum_token.to(device2), origin_mask.to(device2))\n",
    "    \n",
    "  # Dimension Padding\n",
    "  if old_action_prob.size(1) != action_prob.size(1):\n",
    "    print(\"7 ON\", end=\"/\")\n",
    "    max_dim = max(old_action_prob.size(1), action_prob.size(1))\n",
    "    padding_size = abs(action_prob.size(1) - old_action_prob.size(1))\n",
    "\n",
    "    padding_token = tokenizer.pad_token_id\n",
    "\n",
    "    padding_token_matrix = torch.full((action_prob.size(0), padding_size, 50265), padding_token)\n",
    "    action_prob_matrix = torch.zeros((action_prob.size(0), padding_size, 50265))\n",
    "    \n",
    "    action_prob_matrix[ : , :, padding_token] = 1\n",
    "    padding_token_matrix[..., :] = action_prob_matrix\n",
    "\n",
    "    if old_action_prob.size(1) < max_dim:\n",
    "      old_action_prob = torch.cat([old_action_prob, padding_token_matrix], dim=1)\n",
    "    else:\n",
    "      action_prob = torch.cat([action_prob, padding_token_matrix], dim=1)\n",
    "\n",
    "    \n",
    "  # Loss Calculation\n",
    "  action_log_prob = torch.log(action_prob + 1e-8)\n",
    "    \n",
    "  old_action_log_prob = torch.log(old_action_prob + 1e-8)\n",
    "  print(\"8 ON\", end=\"/\")\n",
    "  KL_divergence = F.kl_div(input = old_action_log_prob,\n",
    "                           target = action_log_prob,\n",
    "                           reduction='mean',  # 'none' | 'batchmean' | 'sum' | 'mean'\n",
    "                           log_target=True)\n",
    "\n",
    "  print(\"9 ON\", end=\"/\")\n",
    "  R = reward + KL_divergence\n",
    "\n",
    "  ratio = (action_log_prob - old_action_log_prob).exp()\n",
    "\n",
    "  surr1 = ratio * R\n",
    "\n",
    "  surr2 = (torch.clamp(ratio, 0.8, 1.2)* R)\n",
    "\n",
    "  loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "  optimizer.zero_grad()\n",
    "  print(\"10 ON\", end=\"/\")\n",
    "  loss.backward()\n",
    "  print(\"11 ON\", end=\"/\")\n",
    "  optimizer.step()\n",
    "  \n",
    "  train_loss.append(loss.item())\n",
    "  print(\"LOSS : \", loss.item())\n",
    "  del loss\n",
    "  del action_logits\n",
    "  del action_prob\n",
    "  del old_action_logits\n",
    "  del old_action_prob\n",
    "  del sum_token\n",
    "  del reward\n",
    "  del action_log_prob\n",
    "  del old_action_log_prob\n",
    "  del KL_divergence\n",
    "  del R\n",
    "  del ratio\n",
    "  del surr1\n",
    "  del surr2\n",
    "  \"\"\"\n",
    "  if (index+1)%1 == 0:\n",
    "    mean = sum(train_loss)/len(train_loss)\n",
    "    info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "    end_time = time.time()\n",
    "    print(\"=============================================================================================================================\")\n",
    "    print(f\" Index: {index+1} / {len(train_loader)} \\t LOSS: {mean :.4f} \\t \\n GPU: {100 * (1 - info.free / info.total) :.4f}% used \\t Elapsed Time : {end_time-start_time :.2f}secs \\n\")\n",
    "    train_loss = []\n",
    "  \n",
    "  if (index+1)%10 == 0: \n",
    "    save_model_info(new_policy_model, f\"ver_{(index+1)//300}\")\n",
    "    new_policy_model.to(device)\n",
    "  \"\"\"\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(reward_model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJh7CObCk4TE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iDMYZteMors"
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QuoVpACAPHM7"
   },
   "source": [
    "##### 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2VDFFQuPQoV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_cZgcECPQqk"
   },
   "outputs": [],
   "source": [
    "# def save_model_info(self, _model, _version=\"ver_1\"):\n",
    "#     if not os.path.isdir(\"./policy_model\"):\n",
    "#         os.makedirs(\"./policy_model\")\n",
    "#     # 모델 정보 저장\n",
    "#     _model = _model.cpu()\n",
    "#     torch.save({'model_state_dict': _model.state_dict(),\n",
    "#                 }, f\"./policy_model/policy_model_{_version}.pth\")  #policy_model_ver_1\n",
    "\n",
    "#     print(f\"******************* Model Saved : policy_model_{_version} *******************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jsT3KCRjPUYl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xH9_yVSbPUb7"
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2nQoYlXPnpUb"
   },
   "source": [
    "## [5] Memory 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6m1wsqPFnop2",
    "outputId": "ec2c5856-f420-456b-c204-d9af3ab9051b"
   },
   "outputs": [],
   "source": [
    "# old_action_prob = None\n",
    "\n",
    "# optimizer = optim.AdamW(policy_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# action_prob_list = []\n",
    "\n",
    "# for index, (origin, sum) in enumerate(train_loader):\n",
    "\n",
    "#   # Preparation\n",
    "#   origin_token = tokenizer.batch_encode_plus(origin, padding=True, return_tensors='pt').input_ids.to(device)\n",
    "\n",
    "#   origin_mask = generate_global_attention_mask(tokenizer, origin_token).to(device)\n",
    "\n",
    "#   # Action\n",
    "#   action_logits = policy_model(input_ids = origin_token, global_attention_mask = origin_mask).logits # , labels = sum_token)\n",
    "\n",
    "#   action_prob = torch.softmax(action_logits, dim=-1)\n",
    "\n",
    "#   action_prob = action_prob.squeeze(0).detach().cpu().numpy()\n",
    "#   action_prob_list.append(action_prob)\n",
    "\n",
    "#   if (index+1)%200 ==0:\n",
    "#     print(\"200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6AH8p4A0dTE"
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # 출력 결과를 pickle로 저장\n",
    "# with open('./old_action_200.pickle', 'wb') as f:\n",
    "#     pickle.dump(action_prob_list, f)\n",
    "\n",
    "# # # 불러온 출력 결과 확인\n",
    "# # print(loaded_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "EuxQ_XORqw3-"
   },
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gzb1SWo4bYIv"
   },
   "outputs": [],
   "source": [
    "class RL_Trainer:\n",
    "    def __init__(self, _epoch= EPOCH, _policy_model = policy_model, _reward_model = reward_model, _tokenizer = tokenizer, _lr = LEARNING_RATE, _train_loader = train_loader, _valid_loader = valid_loader):\n",
    "\n",
    "        # Training 관련\n",
    "        self.policy_model = _policy_model\n",
    "        self.reward_model = _reward_model\n",
    "\n",
    "        self.tokenizer = _tokenizer\n",
    "\n",
    "        self.epoch = _epoch\n",
    "\n",
    "        self.optimizer = optim.AdamW(self.policy_model.parameters(), lr=_lr)\n",
    "        ## CHECK: Reward Optimizer 있어야 할 듯 ?\n",
    "\n",
    "        self.train_loader = _train_loader\n",
    "        self.valid_loader = _valid_loader\n",
    "\n",
    "    # 모델 저장\n",
    "    def save_model_info(self, _model, _optimizer, _train_loss = [], _valid_loss= [], _version=\"ver_1\"):\n",
    "        if not os.path.isdir(\"./policy_model\"):\n",
    "            os.makedirs(\"./policy_model\")\n",
    "        # 모델 정보 저장\n",
    "        torch.save({'model_state_dict': _model.state_dict(),\n",
    "                    'optimizer_state_dict': _optimizer.state_dict(),\n",
    "                    'record_list' : {'train_loss': _train_loss, 'valid_loss': _valid_loss},\n",
    "                    }, f\"./policy_model/policy_model_{_version}.pth\")  #reward_model_ver_1\n",
    "\n",
    "        print(f\"model_saved : policy_model_{_version}\")\n",
    "\n",
    "\n",
    "\n",
    "    ''' ======================================= 매   우   중   요 ============================================================='''\n",
    "    # 모델 Training\n",
    "    def train(self):\n",
    "\n",
    "        ## 초기화\n",
    "        train_loss_list = []\n",
    "        valid_loss_list = []\n",
    "\n",
    "        record_train_loss = []\n",
    "        record_valid_loss = []\n",
    "\n",
    "        # Optimizer & Loss function\n",
    "        optimizer = self.optimizer\n",
    "\n",
    "        # Data Loader\n",
    "        train_loader = self.train_loader\n",
    "        valid_loader= self.valid_loader\n",
    "\n",
    "        # 모델 정의\n",
    "        model = self.policy_model\n",
    "        tokenizer = self.tokenizer\n",
    "\n",
    "        # Hyper Parameter\n",
    "        epoch = self.epoch\n",
    "\n",
    "        for i in range(epoch):\n",
    "            start_time = time.time()\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            for index, (original_text, sum_text) in enumerate(train_loader):\n",
    "\n",
    "                original_token = tokenizer.batch_encode_plus(original_text, padding=True, return_tensors='pt').input_ids\n",
    "                sum_token = tokenizer.batch_encode_plus(sum_text, padding=True, return_tensors='pt').input_ids\n",
    "\n",
    "                original_attention_mask = generate_global_attention_mask(tokenizer, original_token)\n",
    "\n",
    "                original_token = original_token.to(device)\n",
    "                original_attention_mask = original_attention_mask.to(device)\n",
    "                sum_token = sum_token.to(device)\n",
    "\n",
    "                output = model(input_ids = original_token,\n",
    "                               global_attention_mask = original_attention_mask,\n",
    "                               labels = sum_token)\n",
    "\n",
    "                # Log Sigmoid\n",
    "                loss = output[0]\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "                end_time = time.time()\n",
    "                train_loss_list.append(loss.item())\n",
    "\n",
    "#                 print(f\"========================{index+1}===========================\")\n",
    "#                 print(f\"Loss : {loss.item()}\")\n",
    "\n",
    "                if (index+1)%200 == 0:\n",
    "                    # Validation loss 계산\n",
    "                    valid_loss_list = []\n",
    "\n",
    "                    ##### 이거 validatoin 끝나고 model.train() 있는지 꼭꼭 확인 #####\n",
    "                    model.eval()\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        for valid_index, (valid_original_text, valid_sum_text) in enumerate(valid_loader):\n",
    "\n",
    "                            original_token = tokenizer.batch_encode_plus(valid_original_text, padding=True, return_tensors='pt').input_ids\n",
    "                            sum_token = tokenizer.batch_encode_plus(valid_sum_text, padding=True, return_tensors='pt').input_ids\n",
    "\n",
    "                            original_attention_mask = generate_global_attention_mask(tokenizer, original_token)\n",
    "\n",
    "                            original_token = original_token.to(device)\n",
    "                            sum_token = sum_token.to(device)\n",
    "                            original_attention_mask= original_attention_mask.to(device)\n",
    "\n",
    "                            valid_output = model(input_ids = original_token,\n",
    "                                                 global_attention_mask = original_attention_mask,\n",
    "                                                 labels = sum_token)\n",
    "\n",
    "                            valid_loss = valid_output[0]\n",
    "                            valid_loss_list.append(valid_loss.item())\n",
    "\n",
    "                            if (valid_index+1)%20 == 0:\n",
    "                                break;\n",
    "\n",
    "                    model.train()\n",
    "\n",
    "                    train_loss_mean = sum(train_loss_list) / len(train_loss_list)\n",
    "                    valid_loss_mean = sum(valid_loss_list) / len(valid_loss_list)\n",
    "\n",
    "                    print(\"==================================================================================\")\n",
    "                    print(f\"Batch {(index+1)}  ({((index+1)/len(train_loader))*100 :.3f} %) \\t \\\n",
    "                            Train Loss : {train_loss_mean :.4f} \\t \\\n",
    "                            Valid Loss : {valid_loss_mean :.4f} \\t \\\n",
    "                            Elapsed Time: {(end_time - start_time) :.2f} sec\")\n",
    "\n",
    "                    train_loss_list = []\n",
    "                    record_train_loss.append(train_loss_mean)\n",
    "                    record_valid_loss.append(valid_loss_mean)\n",
    "\n",
    "                if (index+1)%1000 == 0:\n",
    "                    self.save_model_info(model, optimizer, record_train_loss, record_valid_loss, f\"ver_{(index+1)//1000}\")\n",
    "\n",
    "        return model, record_train_loss, record_valid_loss\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bKYXY2J6bYIw"
   },
   "outputs": [],
   "source": [
    "policy_trainer = RL_Trainer(EPOCH,\n",
    "                                policy_model,\n",
    "                                tokenizer,\n",
    "                                LEARNING_RATE,\n",
    "                                train_loader,\n",
    "                                valid_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GO7JMbSObYIw",
    "outputId": "33c63cbd-17bd-43e8-acd2-a944c03fd412"
   },
   "outputs": [],
   "source": [
    "model, record_train_loss, record_valid_loss = policy_trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "iEn4UL5wbYIw"
   },
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0UuO8GMIbYIw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Uj5fN8hDo8Re"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "021c6095623147418625c3b0b80f27ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "074de416985c4ef78b604475090707d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38fb4e1d2f51411e86c41dfb8d18d5db",
      "placeholder": "​",
      "style": "IPY_MODEL_a183e0e9981a4ded8db6530bcf99912a",
      "value": " 1.84G/1.84G [00:19&lt;00:00, 119MB/s]"
     }
    },
    "10ad05244ea645108a724a56f7419ba3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12b28ffa15824e7f91f743c54167fa31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "13c7353e6f3b4ccfad60e832be00121b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc90d1e7943e4d72b33e558e8b1ad1b6",
      "placeholder": "​",
      "style": "IPY_MODEL_23d6665f672f482cbe9c7ff50799aec3",
      "value": " 1.63k/? [00:00&lt;00:00, 123kB/s]"
     }
    },
    "1420735f82574467a0ba3e8ecaed4b43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1629ebaef4074795863457ecff11c048": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1780de432ade4f61a2086907bc96a4fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bd9297e098f4b2b98526cfb725b013c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c4cba28480447029e01d90fcf9b185d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e5191d117f742f5b2a4151df3101fc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "23d6665f672f482cbe9c7ff50799aec3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "381041138c1643b390a0d379b3455ac5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38fb4e1d2f51411e86c41dfb8d18d5db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b4f9d4f51bd406e97f721ec9584f60b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b7abaa2b8694aa7ac419804cdb5e4b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_381041138c1643b390a0d379b3455ac5",
      "max": 1839633783,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c7cb709c9a734725a25c74d3217754ae",
      "value": 1839633783
     }
    },
    "3c0db56612c94787b5f5fccd74f394df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41272565bee54a8facfea11bdfa41aa2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0c3093b53c1432c9eacb24770355429",
      "max": 207,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1e5191d117f742f5b2a4151df3101fc0",
      "value": 207
     }
    },
    "458f1a29aeee47418454de8d96a81c04": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4923c169d9d84346800d71df46675083": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_90bd4b70b3044893a7412126b3dcb166",
       "IPY_MODEL_41272565bee54a8facfea11bdfa41aa2",
       "IPY_MODEL_a8f7be576e6a4d46bee62d065deee79e"
      ],
      "layout": "IPY_MODEL_021c6095623147418625c3b0b80f27ba"
     }
    },
    "5bc6456f991d4eecb92a228104fec11b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "640d74c65d724110ac417f8fbab76a37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66916ec7aa7f4587a88cb8880967d7d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6db1a3f7785e41c0bd3a97cdc3d0af93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c4cba28480447029e01d90fcf9b185d",
      "placeholder": "​",
      "style": "IPY_MODEL_3c0db56612c94787b5f5fccd74f394df",
      "value": " 2/2 [00:00&lt;00:00, 13.25it/s]"
     }
    },
    "7a16bc6d41f946c68d830bc90a184c49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bc6456f991d4eecb92a228104fec11b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d8e4cf285be145b788354f9313418d00",
      "value": 1
     }
    },
    "8ad2d66a2bad4716bad46f8f3be4f24f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab2c791edad745c8ac03cb80bc924161",
      "max": 1018571383,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_af221a6a4d4149c2be9510a5d6a6b026",
      "value": 1018571383
     }
    },
    "905f2b91fdbd4416a4aaf5d958831951": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9069993d722e4714a1880288bb08e790": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90bd4b70b3044893a7412126b3dcb166": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa048943056948fe8f31bdcceadde9b6",
      "placeholder": "​",
      "style": "IPY_MODEL_12b28ffa15824e7f91f743c54167fa31",
      "value": "Downloading (…)neration_config.json: 100%"
     }
    },
    "926598e17eff4e1f986b8f26d140faca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9fe36dadd26c4ac9919354bb4e2b4a99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0981cbfcc714b9cb1ef692ae98c6ade": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66916ec7aa7f4587a88cb8880967d7d2",
      "placeholder": "​",
      "style": "IPY_MODEL_3b4f9d4f51bd406e97f721ec9584f60b",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "a183e0e9981a4ded8db6530bcf99912a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a8f7be576e6a4d46bee62d065deee79e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fe36dadd26c4ac9919354bb4e2b4a99",
      "placeholder": "​",
      "style": "IPY_MODEL_c23c666a408e4e9ba8de7267d2e0dad8",
      "value": " 207/207 [00:00&lt;00:00, 16.1kB/s]"
     }
    },
    "ab2c791edad745c8ac03cb80bc924161": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "adfb3407896741e0b77286cdc1183011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a0981cbfcc714b9cb1ef692ae98c6ade",
       "IPY_MODEL_8ad2d66a2bad4716bad46f8f3be4f24f",
       "IPY_MODEL_faf53257661e4cc4a8b6ecdefc61027a"
      ],
      "layout": "IPY_MODEL_905f2b91fdbd4416a4aaf5d958831951"
     }
    },
    "af221a6a4d4149c2be9510a5d6a6b026": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b4fc0bf4148f4cab93e93f31c9e40c78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba78a17515964f20939dffe238ece146": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bcaab85650bc4a66a347714e10469aef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10ad05244ea645108a724a56f7419ba3",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1420735f82574467a0ba3e8ecaed4b43",
      "value": 2
     }
    },
    "c23c666a408e4e9ba8de7267d2e0dad8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c254524bd00d458ab44746b4c41dcb40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1780de432ade4f61a2086907bc96a4fe",
      "placeholder": "​",
      "style": "IPY_MODEL_9069993d722e4714a1880288bb08e790",
      "value": "Downloading (…)lve/main/config.json: "
     }
    },
    "c7cb709c9a734725a25c74d3217754ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c9d1ff9d84cb4e1796efbd2f0bd42631": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d3d3523f49264b67bac2e33343e2a4fa",
       "IPY_MODEL_3b7abaa2b8694aa7ac419804cdb5e4b5",
       "IPY_MODEL_074de416985c4ef78b604475090707d9"
      ],
      "layout": "IPY_MODEL_b4fc0bf4148f4cab93e93f31c9e40c78"
     }
    },
    "cc90d1e7943e4d72b33e558e8b1ad1b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3d3523f49264b67bac2e33343e2a4fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1bd9297e098f4b2b98526cfb725b013c",
      "placeholder": "​",
      "style": "IPY_MODEL_ba78a17515964f20939dffe238ece146",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "d62e55e7919340fbac4b5306318be0f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fbaefe5beb4a4881bb491545a730b652",
       "IPY_MODEL_bcaab85650bc4a66a347714e10469aef",
       "IPY_MODEL_6db1a3f7785e41c0bd3a97cdc3d0af93"
      ],
      "layout": "IPY_MODEL_f75fb556375c45f5bc02f66b3b8c7372"
     }
    },
    "d8e4cf285be145b788354f9313418d00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dbba4433df5648cb80594be695954954": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c254524bd00d458ab44746b4c41dcb40",
       "IPY_MODEL_7a16bc6d41f946c68d830bc90a184c49",
       "IPY_MODEL_13c7353e6f3b4ccfad60e832be00121b"
      ],
      "layout": "IPY_MODEL_640d74c65d724110ac417f8fbab76a37"
     }
    },
    "dc1f14103205437ab7ac513906c61f8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0c3093b53c1432c9eacb24770355429": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f75fb556375c45f5bc02f66b3b8c7372": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa048943056948fe8f31bdcceadde9b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "faf53257661e4cc4a8b6ecdefc61027a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_458f1a29aeee47418454de8d96a81c04",
      "placeholder": "​",
      "style": "IPY_MODEL_926598e17eff4e1f986b8f26d140faca",
      "value": " 1.02G/1.02G [00:11&lt;00:00, 89.0MB/s]"
     }
    },
    "fbaefe5beb4a4881bb491545a730b652": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1629ebaef4074795863457ecff11c048",
      "placeholder": "​",
      "style": "IPY_MODEL_dc1f14103205437ab7ac513906c61f8d",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
