{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import LEDTokenizer, LEDModel\n",
    "\n",
    "tokenizer = LEDTokenizer.from_pretrained(\"allenai/led-large-16384-arxiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from copy import deepcopy\n",
    "\n",
    "with open(\"./_FRIDGE/_aug/pubmed_test_aug.pickle\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "data = deepcopy(dataset[:20])\n",
    "\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_global_attention_mask(tokenizer, input_ids):\n",
    "    mask = torch.zeros_like(input_ids)\n",
    "    mask[((input_ids == tokenizer.bos_token_id) | (input_ids == tokenizer.eos_token_id)).nonzero(as_tuple=True)] = 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardModel(nn.Module):\n",
    "    def __init__(self, model=\"allenai/led-large-16384-arxiv\", head_layer_size=32):\n",
    "        super(RewardModel, self).__init__()\n",
    "        self.led_encoder = LEDModel.from_pretrained(model).get_encoder()\n",
    "        self._encoder_output_size = self.led_encoder.layernorm_embedding.weight.shape[0]\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(self._encoder_output_size, head_layer_size, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(head_layer_size, 1, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, global_attention_mask):\n",
    "        hidden_state = self.led_encoder(input_ids, global_attention_mask=global_attention_mask).last_hidden_state\n",
    "        output = hidden_state.view(hidden_state.size(0), -1, hidden_state.size(-1))[:, -1, :]\n",
    "        output = self.head(output)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/led-large-16384-arxiv were not used when initializing LEDModel: ['lm_head.weight', 'final_logits_bias']\n",
      "- This IS expected if you are initializing LEDModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LEDModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "test = RewardModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Criterion():\n",
    "    def __init__(self):\n",
    "        self.logsig = nn.LogSigmoid()\n",
    "    def loss(self, output):\n",
    "        return -self.logsig(output[0] - output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.SGD(test.parameters(), lr=0.001)\n",
    "criterion = Criterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [02:31<47:59, 151.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6836, grad_fn=<NegBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [04:55<44:08, 147.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6833, grad_fn=<NegBackward0>)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for d in tqdm(data):\n",
    "    art = tokenizer.batch_decode(d[\"article\"].unsqueeze(0))[0]\n",
    "    abt = tokenizer.batch_decode(d[\"abstract\"].unsqueeze(0))[0]\n",
    "    nos = tokenizer.batch_decode(d[\"noised\"].unsqueeze(0))[0]\n",
    "\n",
    "    merged_1 = art+\" TL;DR: \"+abt\n",
    "    merged_0 = art+\" TL:DR: \"+nos\n",
    "    \n",
    "    put = tokenizer.batch_encode_plus([merged_1, merged_0], return_tensors=\"pt\", padding=True).input_ids[:, 1:-1]\n",
    "    att = generate_global_attention_mask(tokenizer, put)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    res = test(put, att)\n",
    "    loss = criterion.loss(res)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion.loss(tensor([48792., 2384.]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hg",
   "language": "python",
   "name": "hg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
